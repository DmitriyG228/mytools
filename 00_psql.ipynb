{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import DateTime\n",
    "from sqlalchemy import Boolean\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, Date, String, Text, Float, Boolean, ForeignKey, and_, or_, MetaData\n",
    "from sqlalchemy.orm.exc import NoResultFound, MultipleResultsFound\n",
    "from sqlalchemy.orm import sessionmaker, relationship, backref\n",
    "from sqlalchemy import update\n",
    "from sqlalchemy import desc\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import scoped_session\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.sql.expression import select, exists\n",
    "from IPython.display import clear_output\n",
    "from sqlalchemy import Column, Integer, String ,DateTime,UniqueConstraint,Table\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, relationship, backref\n",
    "from sqlalchemy.dialects.postgresql import ARRAY\n",
    "from sqlalchemy.sql.sqltypes import *\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy.ext.compiler import compiles\n",
    "from sqlalchemy.sql.expression import Executable, ClauseElement #_literal_as_text\n",
    "from sqlalchemy.ext import compiler\n",
    "from sqlalchemy.schema import DDLElement\n",
    "from sqlalchemy.inspection import inspect\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy import VARCHAR\n",
    "\n",
    "from sqlalchemy.dialects.postgresql import JSON\n",
    "\n",
    "from sqlalchemy.dialects.postgresql import REAL\n",
    "\n",
    "from sqlalchemy import cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def docker_run(docker_name,passw,port): \n",
    "    return f'sudo docker run --name {docker_name} -e POSTGRES_PASSWORD={passw} -d -p {port}:5432  -v {docker_v_path} postgres'\n",
    "\n",
    "\n",
    "def pgdump(schema,passw,port):    \n",
    "    now = pd.Timestamp.now()\n",
    "    return f\"pg_dump postgresql://postgres:{passw}@localhost:{port} -n {schema} > {schema}_{now.hour}_{now.day}_{now.month}_{now.year}.sql\"\n",
    "\n",
    "def pgrestore(docker_name, dump_path = False):\n",
    "    if not dump_path:\n",
    "        dumps = path_info(psql_backup_path).sort_values('time')\n",
    "        dump_path = dumps[dumps['name'].str.contains(\".sql\")].iloc[-1]['path']\n",
    "    \n",
    "    return f'cat {dump_path} | docker exec -i {docker_name} psql -U postgres | >> log.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_constraints():\n",
    "    return pd.read_sql(\"\"\"SELECT conrelid::regclass AS table_from\n",
    "                          ,conname\n",
    "                          ,pg_get_constraintdef(c.oid)\n",
    "                    FROM   pg_constraint c\n",
    "                    JOIN   pg_namespace n ON n.oid = c.connamespace\n",
    "                    AND    n.nspname = 'public' -- your schema here\n",
    "                    ORDER  BY conrelid::regclass::text, contype DESC;\"\"\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def du(engine,schema='public',partitions='no'):\n",
    "\n",
    "    df = query(\"\"\"SELECT *, pg_size_pretty(total_bytes) AS total\n",
    "                            , pg_size_pretty(index_bytes) AS INDEX\n",
    "                            , pg_size_pretty(toast_bytes) AS toast\n",
    "                            , pg_size_pretty(table_bytes) AS TABLE\n",
    "                          FROM (\n",
    "                          SELECT *, total_bytes-index_bytes-COALESCE(toast_bytes,0) AS table_bytes FROM (\n",
    "                              SELECT c.oid,\n",
    "                                     nspname AS table_schema,\n",
    "                                     relname AS TABLE_NAME\n",
    "                                      , c.reltuples AS row_estimate\n",
    "                                      , pg_total_relation_size(c.oid) AS total_bytes\n",
    "                                      , pg_indexes_size(c.oid) AS index_bytes\n",
    "                                      , pg_total_relation_size(reltoastrelid) AS toast_bytes\n",
    "                                  FROM pg_class c\n",
    "                                  LEFT JOIN pg_namespace n ON n.oid = c.relnamespace\n",
    "                                  WHERE relkind = 'r'\n",
    "                          ) a\n",
    "                        ) a;\"\"\",engine)\n",
    "    df = df[['table_schema','table_name','row_estimate','total_bytes','index_bytes']].sort_values('row_estimate',ascending=False)\n",
    "    df = df[df['table_schema']==schema]\n",
    "    df['total_bytes']=df['total_bytes']/10**9\n",
    "    df['index_bytes']=df['index_bytes']/10**9\n",
    "    df['row_estimate'] = (df['row_estimate']/1000).astype(int)\n",
    "    df.columns = ['schema','table','mln_rows','total_Gb','index_Gb']\n",
    "\n",
    "    if   partitions== 'no' : df = df[~df['table'].apply(lambda x: True in [xx.isdigit() for xx in x])]\n",
    "    elif partitions== 'yes': df = df[ df['table'].apply(lambda x: True in [xx.isdigit() for xx in x])]\n",
    "    else:                  df = df\n",
    "    return df#.sort_values('index_Gb',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def dtypes(engine,table,schema='public'):\n",
    "    return query(f\"\"\"SELECT\n",
    "                    column_name,\n",
    "                    data_type,\n",
    "                    character_maximum_length AS max_length,\n",
    "                    character_octet_length AS octet_length\n",
    "                FROM\n",
    "                    information_schema.columns\n",
    "                WHERE\n",
    "                    table_schema = '{schema}' AND \n",
    "                    table_name = '{table}';\"\"\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "query = lambda q,engine: pd.read_sql_query(q,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def current():\n",
    "    return query(\"SELECT * FROM pg_stat_activity where state = 'active';\")[['pid','query_start','state_change','wait_event_type','wait_event','query','backend_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kill(pid):\n",
    "    return engine.execute(f'SELECT pg_terminate_backend({pid})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "schema = 'food'\n",
    "LocalBase = declarative_base(metadata=MetaData(schema=schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def insert_on_conflict(df,table,engine,update = False, update_cols = None,unique_cols=[],schema=schema):\n",
    "    metadata = MetaData(schema=schema)\n",
    "    metadata.bind = engine\n",
    "    table = Table(table, metadata, autoload=True)\n",
    "    primary_keys = [key.name for key in inspect(table).primary_key]\n",
    "#     unique_cols = [cc.name for c in list(inspect(table).constraints) for cc in c if type(c) == UniqueConstraint]\n",
    "\n",
    "    insrt_vals = df.to_dict(orient='records')\n",
    "    insrt_stmnt = insert(table).values(insrt_vals)\n",
    "\n",
    "    if update    : \n",
    "        assert update_cols, 'update_cols must be provided if update'\n",
    "        set_ = {c:getattr(insrt_stmnt.excluded, c) for c in update_cols}\n",
    "        do_nothing_stmt  = insrt_stmnt.on_conflict_do_update (index_elements=unique_cols,set_=set_)\n",
    "\n",
    "    else: do_nothing_stmt  = insrt_stmnt.on_conflict_do_nothing(index_elements=unique_cols)\n",
    "\n",
    "    engine.execute(do_nothing_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_sql(table,schema,engine): return pd.read_sql(f'select * from {schema}.{table}',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker create container postgis\n",
    "#docker pull postgres\n",
    "#sudo docker run --name psql_food_prod -e POSTGRES_PASSWORD=KJnbuiwuef89k -d -p 5434:5432 postgres\n",
    "#sudo docker run --name psql_food_dev  -e POSTGRES_PASSWORD=KJnbuiwuef89k -d -p 5433:5432 postgres\n",
    "\n",
    "#dump and restore\n",
    "\n",
    "# pg_dump postgresql://postgres:KJnbuiwuef89k@localhost:5434 -n food > bd.sql\n",
    "#cat bd.sql | docker exec -i psql_food_prod psql -U postgres | >> log.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg_dump -t table_to_copy source_db | psql target_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy table from one database to an other\n",
    "#pg_dump postgresql://postgres:KJnbuiwuef89k@localhost:5432 -t foods_prompted_images | docker exec -i psql_food_prod_1806 psql -U postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytools.paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dima/food_dev/mytools\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/dima/food_dev/mytools\n",
      "Requirement already satisfied: pip in /home/dima/anaconda3/lib/python3.9/site-packages (from mytools==0.0.1) (21.2.4)\n",
      "Requirement already satisfied: packaging in /home/dima/anaconda3/lib/python3.9/site-packages (from mytools==0.0.1) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/dima/anaconda3/lib/python3.9/site-packages (from packaging->mytools==0.0.1) (3.0.4)\n",
      "Installing collected packages: mytools\n",
      "  Attempting uninstall: mytools\n",
      "    Found existing installation: mytools 0.0.1\n",
      "    Uninstalling mytools-0.0.1:\n",
      "      Successfully uninstalled mytools-0.0.1\n",
      "  Running setup.py develop for mytools\n",
      "Successfully installed mytools-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1",
   "language": "python",
   "name": "f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e60dfbe6f5380ba179a6a69b5c6eb8a8f3799b1b5eb5bfe60a7920604506f35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

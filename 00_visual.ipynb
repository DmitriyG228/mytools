{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8969f0b-4c76-45a0-a6ee-5be1c5585743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a406fd79-f0fa-47bd-b053-13692dd9d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from mytools.tools import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CosineSimilarity\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d683fdd-fa9b-403f-ade8-96b578ac027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n",
    "import seaborn as sb\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from PIL import Image\n",
    "plt.rcParams['figure.figsize'] = (70,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1883687-dbdd-4cc4-9093-c9c20ec4189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "series2tensor = lambda series:torch.tensor([np.array(c) for c in series.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2fc16b-23b2-41e2-a4cd-e592d0bf33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def norm(v): \n",
    "    return v/torch.linalg.norm(v, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d13f373-6b6c-4ec8-b462-c34c4ada74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "cos = CosineSimilarity(dim=1, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f974b-bdf5-452f-90d8-24839afd9376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f801228-5ddd-4b3b-9e63-fecde77b1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#https://stackoverflow.com/questions/59831211/neighbours-of-a-cell-in-matrix-pytorch\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "def mean_filter(x_bchw):\n",
    "    \"\"\"\n",
    "    Calculating the mean of each 3x3 neighborhood.\n",
    "    input:\n",
    "    - x_bchw: input tensor of dimensions batch-channel-height-width\n",
    "    output:\n",
    "    - y_bchw: each element in y is the average of the 9 corresponding elements in x_bchw\n",
    "    \"\"\"\n",
    "    # define the filter\n",
    "    box = torch.ones((3, 3), dtype=x_bchw.dtype, device=x_bchw.device, requires_grad=False)  \n",
    "    box = box / box.sum()\n",
    "    box = box[None, None, ...].repeat(x_bchw.size(1), 1, 1, 1)\n",
    "    # use grouped convolution - so each channel is averaged separately.  \n",
    "    y_bchw = nnf.conv2d(x_bchw, box, padding=1, groups=x_bchw.size(1))\n",
    "    return y_bchw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deaf8bdc-2309-469a-b5a8-cce38484b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def visualize_array(array,back_img = None,alpha=0.3,size = 500,colors = [\"white\",\"lime\",\"green\",\"yellow\",\"orange\", \"red\",\"purple\"],values = [0,1,50,100,200,300,400],vmin=5):\n",
    "\n",
    "    l = list(zip([v/max(values) for v in values],colors))\n",
    "    cmap=LinearSegmentedColormap.from_list('hmap',l)\n",
    "    if back_img and not array.T.shape == back_img.size:array = extrapolate(array,size = size)\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "    sb.heatmap(array, alpha=0.8,cmap=cmap,vmin=vmin, vmax=max(values),cbar=False)\n",
    "    if back_img: ax.imshow(back_img, interpolation='none', alpha=1)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b530a43b-860a-428a-b0c7-f80b193b53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extrapolate(t,factor=None,size=None):\n",
    "    t     = torch.Tensor(t)\n",
    "    t     = t.unsqueeze(0)\n",
    "    t     = torch.nn.functional.upsample(t, scale_factor=factor,size=size)\n",
    "    t     = t.squeeze(0).T.unsqueeze(0)\n",
    "    t     = torch.nn.functional.upsample(t, scale_factor=factor,size=size)\n",
    "    return  t.squeeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9db41f5-705b-472f-b07c-8294a3809421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def expand_boundaries(t,times=5,factor=5):\n",
    "    init_size = t.shape[0]\n",
    "    t = extrapolate(t,factor=1/factor)\n",
    "    t = t[None, None, ...].repeat(t.size(1), 1, 1, 1)\n",
    "    for _ in range(times):\n",
    "        t = mean_filter(t)\n",
    "        t[t>0] = 1\n",
    "\n",
    "    t = t[0,0,:]\n",
    "    return extrapolate(t,size=init_size).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed018e7-0e60-45df-86ee-1fa7dea123c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crop_center_arr(arr,shape):\n",
    "    left  = int((arr.shape[1]-shape)/2)\n",
    "    right =      left+shape  \n",
    "    up    = int((arr.shape[0]-shape)/2)\n",
    "    down  =      up+shape \n",
    "    return arr[left:right, up:down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1aee074-80e0-411a-b6e4-3dc46b7717b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_mask(img,mask):\n",
    "    mask = np.array(mask).astype('int')\n",
    "    img = np.array(img)\n",
    "    # if img[:,:,0].shape !=mask.shape: \n",
    "    #     df = pd.DataFrame([mask.shape,img.shape[:-1]])\n",
    "    #     df.iloc[0] = -df.iloc[0]\n",
    "    #     mask = mask[:-1,:] if df.sum().tolist() ==[0, -1]  else mask[:,:-1]\n",
    "        \n",
    "    \n",
    "    return img * np.stack([mask]*3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c2bf0d2-eede-42b2-9ef3-8caac66b37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crop_zeros(img_arr):\n",
    "\n",
    "    true_points = np.argwhere(img_arr)\n",
    "    top_left = true_points.min(axis=0)\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "    return (img_arr[top_left[0]:bottom_right[0]+1,\n",
    "                      top_left[1]:bottom_right[1]+1]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e13c551-cf8b-4198-9c67-208b52ab5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def crop_image_to_square(img,get_adj = False):\n",
    "    size = max(img.size)\n",
    "\n",
    "    x_adj = int((img.size[0]-size)/2)\n",
    "    y_adj = int((img.size[1]-size)/2)\n",
    "    \n",
    "    \n",
    "    img =  img.crop((x_adj,y_adj,size+x_adj,size+y_adj))\n",
    "    \n",
    "    \n",
    "    if get_adj: return img, (x_adj,y_adj,size)\n",
    "    else      : return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d114517d-4562-4939-b3bc-7e4fa9eb8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://dima.grankin.eu/reference_images/AgACAgIAAxkBAAIKAmLhn0SdD55hleSPR5q57eb-6Lb2AAIZvzEb6jQQS7YEy1gu7EwnAQADAgADeQADKQQ'\n",
    "url = 'https://image.shutterstock.com/z/stock-photo-healthy-lunch-box-with-sandwich-and-fresh-vegetables-bottle-of-water-and-fruits-on-wooden-568229575.jpg'\n",
    "\n",
    "img = get_image_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ef2820-ff96-4442-ab27-2394d502a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = crop_image_to_square(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f93e23a1-0bd8-4dd6-b90d-fc9334c8a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_clip(url):\n",
    "    return torch.tensor(requests.post(f'http://127.0.0.1:8182/image2vector/?url={url}').json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cf2019f-66b3-4ca4-a8ac-b489a764d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_clip(text):\n",
    "    return torch.tensor(requests.post(f'http://127.0.0.1:8182/text2vector/?text={text}').json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ea50f1-45a4-4e68-bd58-c20f08d71682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def search_clip(url,foods,food_clips,prompt_clip=None, head = 1,prompt_factor=3):\n",
    "    clip = get_image_clip(url)\n",
    "    if prompt_clip is not None:\n",
    "        diff = prompt_clip - clip\n",
    "        clip = clip + diff*prompt_factor\n",
    "    df = foods.copy()\n",
    "    df['score'] = cos(food_clips,clip)\n",
    "    df = df.sort_values('score',ascending=False)[:head]\n",
    "\n",
    "    return clip,df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7be3786-74a8-473e-a3b8-8c40993508e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_id=''\n",
    "\n",
    "url = 'https://image.shutterstock.com/z/stock-photo-white-plate-of-orange-pumpkin-soup-on-the-table-studio-shot-1909804795.jpg'\n",
    "img = get_image_from_url(url)\n",
    "img = crop_image_to_square(img)\n",
    "total_size = img.size[0]*img.size[1]\n",
    "\n",
    "i = np.asarray(img, dtype=\"uint8\")\n",
    "i = np.flip(i,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f96dbf8-bf13-4b29-862e-57dbd8e0cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 100\n",
    "ones = torch.ones(s,s)\n",
    "t = torch.zeros(1000,1000)\n",
    "x=600\n",
    "y=600\n",
    "t[x:x+s,y:y+s] = ones\n",
    "x=700\n",
    "y=700\n",
    "t[x:x+s,y:y+s] = ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e07c23-cb1d-4c66-9eb4-3212651c6564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69aac4bc-fb35-4a5e-a60d-fd6520fff6dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisualize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mvisualize_array\u001b[0;34m(array, back_img, alpha, size, colors, values, vmin)\u001b[0m\n\u001b[1;32m      4\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m([v\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(values) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values],colors))\n\u001b[1;32m      5\u001b[0m cmap\u001b[38;5;241m=\u001b[39mLinearSegmentedColormap\u001b[38;5;241m.\u001b[39mfrom_list(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhmap\u001b[39m\u001b[38;5;124m'\u001b[39m,l)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m array\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m \u001b[43mback_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m:array \u001b[38;5;241m=\u001b[39m extrapolate(array,size \u001b[38;5;241m=\u001b[39m size)\n\u001b[1;32m      7\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m15\u001b[39m))\n\u001b[1;32m      8\u001b[0m ax\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_visible(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "visualize_array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a3df3-a237-497b-a256-b3f11e33d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = expand_boundaries(t,times=5,factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ffab0-3638-4a82-bb91-11b18557c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25143e-858b-4efe-ae0a-e8cc42c82dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_array(t.numpy()+tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba6cfa5e-6c0c-4245-a794-350fe1977622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "/bin/bash: nbdev_build_lib: command not found\n"
     ]
    }
   ],
   "source": [
    "!conda activate f4; nbdev_build_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39ff9f-7f05-49b4-8b54-39482f5ac7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f4",
   "language": "python",
   "name": "f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958a698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45524f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from mytools.tools import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CosineSimilarity\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4d53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n",
    "import seaborn as sb\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from PIL import Image\n",
    "plt.rcParams['figure.figsize'] = (70,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab85f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "series2tensor = lambda series:torch.tensor([np.array(c) for c in series.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b9fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def norm(v): \n",
    "    return v/torch.linalg.norm(v, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba94a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "cos = CosineSimilarity(dim=1, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7d9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bdbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#https://stackoverflow.com/questions/59831211/neighbours-of-a-cell-in-matrix-pytorch\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "def mean_filter(x_bchw):\n",
    "    \"\"\"\n",
    "    Calculating the mean of each 3x3 neighborhood.\n",
    "    input:\n",
    "    - x_bchw: input tensor of dimensions batch-channel-height-width\n",
    "    output:\n",
    "    - y_bchw: each element in y is the average of the 9 corresponding elements in x_bchw\n",
    "    \"\"\"\n",
    "    # define the filter\n",
    "    box = torch.ones((3, 3), dtype=x_bchw.dtype, device=x_bchw.device, requires_grad=False)  \n",
    "    box = box / box.sum()\n",
    "    box = box[None, None, ...].repeat(x_bchw.size(1), 1, 1, 1)\n",
    "    # use grouped convolution - so each channel is averaged separately.  \n",
    "    y_bchw = nnf.conv2d(x_bchw, box, padding=1, groups=x_bchw.size(1))\n",
    "    return y_bchw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f65305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def visualize_array(array,back_img = None,alpha=0.3,size = 500,colors = [\"white\",\"lime\",\"green\",\"yellow\",\"orange\", \"red\",\"purple\"],values = [0,1,50,100,200,300,400],vmin=5):\n",
    "\n",
    "    l = list(zip([v/max(values) for v in values],colors))\n",
    "    cmap=LinearSegmentedColormap.from_list('hmap',l)\n",
    "    if back_img and not array.T.shape == back_img.size:array = extrapolate(array,size = size)\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "    sb.heatmap(array, alpha=0.8,cmap=cmap,vmin=vmin, vmax=max(values),cbar=False)\n",
    "    if back_img: ax.imshow(back_img, interpolation='none', alpha=1)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d2c2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extrapolate(t,factor=None,size=None):\n",
    "    t     = torch.Tensor(t)\n",
    "    t     = t.unsqueeze(0)\n",
    "    t     = torch.nn.functional.upsample(t, scale_factor=factor,size=size)\n",
    "    t     = t.squeeze(0).T.unsqueeze(0)\n",
    "    t     = torch.nn.functional.upsample(t, scale_factor=factor,size=size)\n",
    "    return  t.squeeze(0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70991b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def expand_boundaries(t,times=5,factor=5):\n",
    "    init_size = t.shape[0]\n",
    "    t = extrapolate(t,factor=1/factor)\n",
    "    t = t[None, None, ...].repeat(t.size(1), 1, 1, 1)\n",
    "    for _ in range(times):\n",
    "        t = mean_filter(t)\n",
    "        t[t>0] = 1\n",
    "\n",
    "    t = t[0,0,:]\n",
    "    return extrapolate(t,size=init_size).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27feb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def crop_center_arr(arr,shape):\n",
    "    left  = int((arr.shape[1]-shape)/2)\n",
    "    right =      left+shape  \n",
    "    up    = int((arr.shape[0]-shape)/2)\n",
    "    down  =      up+shape \n",
    "    return arr[left:right, up:down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ea3a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def apply_mask(img,mask):\n",
    "    mask = np.array(mask).astype('int')\n",
    "    img = np.array(img)\n",
    "    # if img[:,:,0].shape !=mask.shape: \n",
    "    #     df = pd.DataFrame([mask.shape,img.shape[:-1]])\n",
    "    #     df.iloc[0] = -df.iloc[0]\n",
    "    #     mask = mask[:-1,:] if df.sum().tolist() ==[0, -1]  else mask[:,:-1]\n",
    "        \n",
    "    \n",
    "    return img * np.stack([mask]*3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2b1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def crop_zeros(img_arr):\n",
    "\n",
    "    true_points = np.argwhere(img_arr)\n",
    "    top_left = true_points.min(axis=0)\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "    return (img_arr[top_left[0]:bottom_right[0]+1,\n",
    "                      top_left[1]:bottom_right[1]+1]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79cf4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def crop_image_to_square(img,get_adj = False):\n",
    "    size = max(img.size)\n",
    "\n",
    "    x_adj = int((img.size[0]-size)/2)\n",
    "    y_adj = int((img.size[1]-size)/2)\n",
    "    \n",
    "    \n",
    "    img =  img.crop((x_adj,y_adj,size+x_adj,size+y_adj))\n",
    "    \n",
    "    \n",
    "    if get_adj: return img, (x_adj,y_adj,size)\n",
    "    else      : return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab18f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://dima.grankin.eu/reference_images/AgACAgIAAxkBAAIKAmLhn0SdD55hleSPR5q57eb-6Lb2AAIZvzEb6jQQS7YEy1gu7EwnAQADAgADeQADKQQ'\n",
    "url = 'https://image.shutterstock.com/z/stock-photo-healthy-lunch-box-with-sandwich-and-fresh-vegetables-bottle-of-water-and-fruits-on-wooden-568229575.jpg'\n",
    "\n",
    "img = get_image_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a57235d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = crop_image_to_square(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8028300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_image_clip(url):\n",
    "    return torch.tensor(requests.post(f'http://127.0.0.1:8182/image2vector/?url={url}').json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e6631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_text_clip(text):\n",
    "    return torch.tensor(requests.post(f'http://127.0.0.1:8182/text2vector/?text={text}').json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95dbace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def search_clip(url,foods,food_clips,prompt_clip=None, head = 1,prompt_factor=3):\n",
    "    clip = get_image_clip(url)\n",
    "    if prompt_clip is not None:\n",
    "        diff = prompt_clip - clip\n",
    "        clip = clip + diff*prompt_factor\n",
    "    df = foods.copy()\n",
    "    df['score'] = cos(food_clips,clip)\n",
    "    df = df.sort_values('score',ascending=False)[:head]\n",
    "\n",
    "    return clip,df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "216afa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_id=''\n",
    "\n",
    "url = 'https://image.shutterstock.com/z/stock-photo-white-plate-of-orange-pumpkin-soup-on-the-table-studio-shot-1909804795.jpg'\n",
    "img = get_image_from_url(url)\n",
    "img = crop_image_to_square(img)\n",
    "total_size = img.size[0]*img.size[1]\n",
    "\n",
    "i = np.asarray(img, dtype=\"uint8\")\n",
    "i = np.flip(i,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa039508",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 100\n",
    "ones = torch.ones(s,s)\n",
    "t = torch.zeros(1000,1000)\n",
    "x=600\n",
    "y=600\n",
    "t[x:x+s,y:y+s] = ones\n",
    "x=700\n",
    "y=700\n",
    "t[x:x+s,y:y+s] = ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce930ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97d12950",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efbdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = expand_boundaries(t,times=5,factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde4a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_array(t.numpy()+tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4913c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603d087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f4",
   "language": "python",
   "name": "f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
